<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="OVM3D-Det: Training an Open-Vocabulary Monocular 3D Object Detection Model without 3D Data">
  <meta name="keywords" content="OVM3D-Det, open-vocabulary 3D detection, monocular 3D object detection, open-vocabulary monocular 3D object detection">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>OVM3D-Det: Training an Open-Vocabulary Monocular 3D Object Detection Model without 3D Data</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <!-- <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script> -->

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <!-- <link rel="icon" href="./static/images/favicon.svg"> -->

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<!-- <nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://keunhong.com">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://hypernerf.github.io">
            HyperNeRF
          </a>
          <a class="navbar-item" href="https://nerfies.github.io">
            Nerfies
          </a>
          <a class="navbar-item" href="https://latentfusion.github.io">
            LatentFusion
          </a>
          <a class="navbar-item" href="https://photoshape.github.io">
            PhotoShape
          </a>
        </div>
      </div>
    </div>

  </div>
</nav>
 -->
 
<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">OVM3D-Det</h1>
          <!-- <h1 class="title is-3 publication-title">Learning <span style="color: rgb(38, 195, 38);">Fine-Grained</span> <span style="color: rgb(0, 140, 255);">Class-Agnostic</span> 3D Segmentation<br>without Manual Labels</h1> -->
          <h1 class="title is-3 publication-title">Training an Open-Vocabulary Monocular 3D Object Detection Model without 3D Data</h1>
          <div class="is-size-4"><b>NeurIPS 2024</b></div>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=ieN4b1QAAAAJ&hl=zh-CN&oi=sra">Rui Huang</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=gZCggycAAAAJ&hl=en">Henry Zheng</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://research.nvidia.com/labs/avg/author/yan-wang/">Yan Wang</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="https://www.zhuofanxia.xyz/">Zhuofan Xia</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://profiles.stanford.edu/marco-pavone">Marco Pavone</a><sup>2,3</sup>,
            </span>
            <span class="author-block">
              <a href="https://www.gaohuang.net/">Gao Huang</a><sup>1,4*</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Tsinghua University,</span>
            <span class="author-block"><sup>2</sup>NVIDIA Research,</span>
            <span class="author-block"><sup>3</sup>Stanford University,</span>
            <span class="author-block"><sup>4</sup>Beijing Academy of Artificial Intelligence,</span>
          </div>
          <div class="is-size-6 publication-authors">
            <sup>*</sup>Corresponding author
          </div>
          <div class="is-size-6 publication-authors">
            contact: hr20 (at) mails (dot) tsinghua (dot) edu (dot) cn
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <!-- <span class="link-block">
                <a href="https://arxiv.org/pdf/2011.12948"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span> -->
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark" disabled="">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Video Link. -->
              <span class="link-block">
                <a href="https://youtu.be/SEvCJghi6Ng"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark" disabled="">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
                  <!-- <a href=""
                   class="external-link button is-normal is-rounded is-dark" disabled="">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a> -->
              </span>
              <!-- Dataset Link. -->
              <!-- <span class="link-block">
                <a href="https://mix3d-demo.nekrasov.dev/segment3d/"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Demo</span>
                  </a> -->
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- <div class="container is-max-desktop">
  <div class="columns is-centered has-text-centered">
    <div class="column is-four-fifths">
      <h2 class="title is-3">Abstract</h2>
      <div class="content has-text-justified"> -->

<!-- 

<section class="hero is-light is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-steve">
          <video poster="" id="steve" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/steve.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-chair-tp">
          <video poster="" id="chair-tp" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/chair-tp.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-shiba">
          <video poster="" id="shiba" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/shiba.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-fullbody">
          <video poster="" id="fullbody" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/fullbody.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-blueshirt">
          <video poster="" id="blueshirt" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/blueshirt.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-mask">
          <video poster="" id="mask" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/mask.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-coffee">
          <video poster="" id="coffee" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/coffee.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-toby">
          <video poster="" id="toby" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/toby2.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section> -->


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <!-- <div class="column is-four-fifths"> -->
      <div class="column">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Open-vocabulary 3D object detection has recently attracted considerable attention due to its broad applications in autonomous driving and robotics, 
            aiming to recognize novel classes in previously unseen domains. 
            However, existing point cloud-based models are limited by their high deployment costs. 
            In this work, we propose a novel open-vocabulary monocular 3D object detection framework, dubbed OVM3D-Det, 
            which trains detectors using only RGB images, 
            making it both cost-effective and scalable to publicly available data.
            Unlike traditional methods, OVM3D-Det does not require high-precision LiDAR or 3D sensor data for either input or generating 3D bounding boxes. 
            Instead, it employs open-vocabulary 2D models and pseudo-LiDAR to automatically label 3D objects in RGB images, 
            fostering the learning of open-vocabulary monocular 3D detectors. 
          </p>
          <img src="./static/images/teaser.png" class="teaser-fig" alt="teaser-fig." />
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

    <!-- Paper video. -->
    <!-- <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Video</h2>
        <div class="publication-video">
          <iframe src="https://www.youtube.com/embed/MrKrnHhk8IA?rel=0&amp;showinfo=0"
                  frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
        </div>
      </div>
    </div> -->
    <!--/ Paper video. -->
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Challenge. -->
    <div class="columns is-centered has-text-centered">
      <!-- <div class="column is-four-fifths"> -->
      <div class="column">
        <h2 class="title is-3">Challenge</h2>
        <div class="content has-text-justified">
          <p>
            However, training 3D models with labels directly derived from pseudo-LiDAR is inadequate due to imprecise boxes estimated from noisy point clouds and severely occluded objects. 
            To address these issues, we introduce two innovative designs: adaptive pseudo-LiDAR erosion and bounding box refinement with prior knowledge from large language models. 
            These techniques effectively calibrate the 3D labels and enable RGB-only training for 3D detectors. 
            Extensive experiments demonstrate the superiority of OVM3D-Det over baselines in both indoor and outdoor scenarios.
          </p>
          <img src="./static/images/challenge.png" class="teaser-fig" alt="teaser-fig." />
        </div>
      </div>
    </div>
    <!--/ Challenge. -->
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column">
        <h2 class="title is-3">Methodology</h2>
        <img src="./static/images/framework.png"
                  class="teaser-fig"
                  alt="teaser-fig."/>
        <div class="content has-text-justified">
          <p>
            The overall framework of <strong>OVM3D-Det</strong>. 
            Step 1: Generate per-instance pseudo-LiDAR. 
            Step 2: Apply an adaptive erosion process to remove artifacts and noises. 
            Step 3: Estimate the orientation. 
            Step 4: Tightly fit a box and utilize object priors to assess the estimated box; 
            if deemed unreasonable, search for the optimal box. 
            Step 5: Train the model with pseudo labels.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Exp. -->
    <div class="columns is-centered has-text-centered">
      <div class="column">
        <h2 class="title is-3">Results</h2>

        <h3 class="title is-4">Open-vocabulary monocular 3D object detection results on indoor datasets</h3>
        <img src="./static/images/indoor.png"
                  class="teaser-fig"
                  alt="teaser-fig."/>
        <div class="content has-text-justified">
          <!-- <p>
            OVM3D-Det also achieves state-of-the-art performance on the SUN RGB-D dataset, 
            outperforming existing methods by a large margin. 
            The results demonstrate the effectiveness of our proposed method in open-vocabulary monocular 3D object detection.
          </p> -->
        </div>

        <h3 class="title is-4">Open-vocabulary monocular 3D object detection results on outdoor datasets</h3>
        <img src="./static/images/outdoor.png"
                  class="teaser-fig"
                  alt="teaser-fig."/>
        <div class="content has-text-justified">
          <!-- <p>
            OVM3D-Det achieves state-of-the-art performance on the KITTI dataset, 
            outperforming existing methods by a large margin. 
            The results demonstrate the effectiveness of our proposed method in open-vocabulary monocular 3D object detection.
          </p> -->
        </div>

        <h3 class="title is-4">Visualizations</h3>
        <img src="./static/images/indoor_vis.png"
                  class="teaser-fig"
                  alt="teaser-fig."/>
        <br>
        <img src="./static/images/outdoor_vis.png"
                  class="teaser-fig"
                  alt="teaser-fig."/>

      </div>
    </div>
    <!--/ Exp. -->
  </div>
</section>




<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>
      @inproceedings{huang2024training,
          title={Training an Open-Vocabulary Monocular 3D Detection Model without 3D Data},
          author={Rui Huang and Henry Zheng and Yan Wang and Zhuofan Xia and Marco Pavone and Gao Huang},
          booktitle={The Thirty-eighth Annual Conference on Neural Information Processing Systems},
          year={2024},
          url={https://openreview.net/forum?id=EFkw0OgZOr}
      }</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <!-- <div class="content has-text-centered">
      <a class="icon-link"
         href="./static/videos/nerfies_paper.pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/keunhong" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div> -->
    <div class="columns is-centered">
      <!-- <div class="column is-8"> -->
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            It borrows the source code of <a
              href="https://nerfies.github.io/">this website</a>,
              We sincerely thank <a
              href="https://keunhong.com/">Keunhong Park</a> for developing and open-sourcing this template.
          </p>
        </div>
      <!-- </div> -->
    </div>
  </div>
</footer>

</body>
</html>
